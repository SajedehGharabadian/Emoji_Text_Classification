{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3MJkVdQJi1R6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "gwQycHsYO6Wp"
      },
      "outputs": [],
      "source": [
        "class EmojiTextClassifier:\n",
        "    def __init__(self,vector_shape):\n",
        "        self.vector_shape = vector_shape\n",
        "\n",
        "    def load_dataset(self,dataset_path):\n",
        "        self.df = pd.read_csv(dataset_path)\n",
        "        self.X = np.array(self.df['sentence'],dtype=object)\n",
        "        self.Y = np.array(self.df['label'],dtype=int)\n",
        "        return self.X,self.Y\n",
        "\n",
        "    def load_features_vector(self,file_txt_path):\n",
        "        self.f = open(file_txt_path,encoding='utf-8')\n",
        "        self.word_vectors = {}\n",
        "        for line in self.f:\n",
        "            line = line.strip().split()\n",
        "            word = line[0]\n",
        "            vector = np.array(line[1:],dtype=np.float64)\n",
        "            self.word_vectors[word] = vector\n",
        "\n",
        "        return self.word_vectors\n",
        "\n",
        "\n",
        "    def sentence_to_feature_vectors_avg(self,sentence):\n",
        "          self.sentence = sentence.lower()\n",
        "          words = self.sentence.strip().split(' ')\n",
        "          sum_vectors = np.zeros((self.vector_shape,))\n",
        "          for word in words:\n",
        "              sum_vectors += self.word_vectors[word]\n",
        "\n",
        "          avg_words = sum_vectors / len(words)\n",
        "\n",
        "          return avg_words\n",
        "\n",
        "\n",
        "    def preprocess(self,X,Y):\n",
        "        self.X_avg = []\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        for x in X:\n",
        "            self.X_avg.append(self.sentence_to_feature_vectors_avg(x))\n",
        "\n",
        "\n",
        "        self.X_avg = np.array(self.X_avg).astype('float32')\n",
        "        self.Y_one_hot = tf.keras.utils.to_categorical(self.Y,num_classes=5)\n",
        "\n",
        "        return self.X_avg,self.Y_one_hot\n",
        "\n",
        "    def load_model(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dropout(0.1),\n",
        "            tf.keras.layers.Dense(5,input_shape=(self.vector_shape,),activation='softmax')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    def train(self,X_train,Y_train,epochs):\n",
        "        #self.input_shape =input_shape\n",
        "        self.X_train_avg,self.Y_train_one_hot = self.preprocess(X_train,Y_train)\n",
        "        print(self.X_train_avg.shape,self.Y_train_one_hot.shape)\n",
        "        self.model = self.load_model()\n",
        "        self.model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        #self.model.fit(self.X_train_avg,self.Y_train_one_hot,epochs)\n",
        "        return self.model\n",
        "\n",
        "    def test(self,model,X_test,Y_test):\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        #self.X_test_avg,self.Y_test_one_hot = self.preprocess(self.X_test,self.Y_test)\n",
        "        self.X_avg = []\n",
        "        self.new_Y_test = []\n",
        "        i = 0\n",
        "\n",
        "        for index,x in enumerate(self.X_test):\n",
        "            if x.endswith('\\t') == True:\n",
        "              self.X_avg.append(self.sentence_to_feature_vectors_avg(x))\n",
        "              self.new_Y_test.append(self.Y_test[index])\n",
        "\n",
        "\n",
        "\n",
        "        self.X_avg = np.array(self.X_avg)\n",
        "        self.new_Y_test = np.array(self.new_Y_test)\n",
        "        self.Y_one_hot = tf.keras.utils.to_categorical(self.new_Y_test,num_classes=5)\n",
        "        print(np.shape(self.X_avg),np.shape(self.Y_one_hot))\n",
        "\n",
        "        accuracy,loss = model.evaluate(self.X_avg,self.Y_one_hot)\n",
        "\n",
        "        return accuracy,loss\n",
        "\n",
        "    def label_to_emoji(self,label):\n",
        "        self.label = label\n",
        "        emojies=['‚ù§Ô∏è','‚öæ','üòä','üòû','üç¥']\n",
        "\n",
        "        return emojies[self.label]\n",
        "\n",
        "    def predict(self,sentece_test):\n",
        "        start_time = time.time()\n",
        "        self.sentence_test = sentece_test\n",
        "        self.my_test_avg = self.sentence_to_feature_vectors_avg(self.sentence_test)\n",
        "        self.my_test_avg = np.array([self.my_test_avg])\n",
        "        self.result = self.model.predict(self.my_test_avg)\n",
        "        y_pred = np.argmax(self.result)\n",
        "\n",
        "        return self.label_to_emoji(y_pred),time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDTk0DJZ8s3S"
      },
      "source": [
        "## 50 Dimention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "a7mnieGdHIxv"
      },
      "outputs": [],
      "source": [
        "emoji_text_50d = EmojiTextClassifier(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJprK7wxyUB6"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = emoji_text_50d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test= emoji_text_50d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')\n",
        "\n",
        "emoji_text_50d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.50d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_50d.preprocess(X_train,Y_train)\n",
        "#model = emoji_text_50d.load_model(input_shape=50)\n",
        "model=emoji_text_50d.train(X_train,Y_train,epochs=300)\n",
        "model.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ymOM6OR1Yb-",
        "outputId": "ea510b3d-b294-41cd-be33-44a69e399263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.8571\n"
          ]
        }
      ],
      "source": [
        "accuracy,loss = emoji_text_50d.test(model,X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTP7FPwcgxQx",
        "outputId": "863ec56c-dcc7-4203-c1c2-3c0c8115252f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 112ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('üòä', 0.18008732795715332)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'the Weather is Sunny'\n",
        "emoji,timer = emoji_text_50d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhPll3d689WU"
      },
      "source": [
        "## 100 Dimention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "PpacYOMKNb2h"
      },
      "outputs": [],
      "source": [
        "emoji_text_100d = EmojiTextClassifier(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "juLYcCDbFhXL"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD2WfmZC1Enp"
      },
      "outputs": [],
      "source": [
        "emoji_text_100d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.100d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_100d.preprocess(X_train,Y_train)\n",
        "model_100 = emoji_text_100d.train(X_train,Y_train,epochs=300)\n",
        "model_100.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDbAt3Ig9ScK",
        "outputId": "1b0ac2f1-7183-47af-de8b-27412cccd207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49, 100) (49, 5)\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.8163\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.6888834834098816, 0.8163265585899353)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss,accuracy= emoji_text_100d.test(model_100,X_test,Y_test)\n",
        "loss,accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL_nZQ9zI04H",
        "outputId": "064233e4-09c3-45f8-ace8-ee2a20381897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 57ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('üòû', 14.203638792037964)"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'I hate Cloudy weather'\n",
        "emoji,timer = emoji_text_100d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7utGZ0qxH9tN"
      },
      "source": [
        "## 200 Dimention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "QmyAqYQujlQX"
      },
      "outputs": [],
      "source": [
        "emoji_text_200d = EmojiTextClassifier(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "QnPq7TjUGErw"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zUs4AGYGFaj",
        "outputId": "8faa0595-e6af-40c5-e5d6-568f8fb84b30"
      },
      "outputs": [],
      "source": [
        "emoji_text_200d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.200d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_200d.preprocess(X_train,Y_train)\n",
        "model_200 = emoji_text_200d.train(X_train,Y_train,epochs=300)\n",
        "model_200.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4LDkL9EGSLx",
        "outputId": "9f1b7360-35f1-42d9-aabb-46b1059aff41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f91e8575e10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5233 - accuracy: 0.8163\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.5232657194137573, 0.8163265585899353)"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss,accuracy= emoji_text_200d.test(model_200,X_test,Y_test)\n",
        "loss,accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBHosyI2GV1y",
        "outputId": "3c81bedf-db34-4809-cbe1-15d8bac89066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('‚ù§Ô∏è', 0.11483097076416016)"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'I love rainy weather'\n",
        "emoji,timer = emoji_text_200d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yM0WOndMwqd"
      },
      "source": [
        "## 300 Dimentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "_ST0L6XsMsHB"
      },
      "outputs": [],
      "source": [
        "emoji_text_300d = EmojiTextClassifier(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "e5dKGHwgNFVj"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwFbfhkXToK3",
        "outputId": "d3d7d40a-8dfd-4c54-e744-1a89784c30cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(132, 300) (132, 5)\n",
            "Epoch 1/300\n",
            "5/5 [==============================] - 1s 17ms/step - loss: 1.6810 - accuracy: 0.1894\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6276 - accuracy: 0.2424\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.5764 - accuracy: 0.2273\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5356 - accuracy: 0.2879\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4874 - accuracy: 0.3485\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4491 - accuracy: 0.3409\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4342 - accuracy: 0.3409\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4034 - accuracy: 0.3712\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3587 - accuracy: 0.4318\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3503 - accuracy: 0.4545\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3096 - accuracy: 0.4545\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2862 - accuracy: 0.5227\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2777 - accuracy: 0.5455\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2482 - accuracy: 0.5455\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2456 - accuracy: 0.5606\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.2234 - accuracy: 0.5758\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.2024 - accuracy: 0.6136\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1772 - accuracy: 0.6667\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1582 - accuracy: 0.6439\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1446 - accuracy: 0.6894\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1372 - accuracy: 0.7197\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0976 - accuracy: 0.6970\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1028 - accuracy: 0.7197\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0919 - accuracy: 0.7121\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0619 - accuracy: 0.7500\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0428 - accuracy: 0.7879\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0376 - accuracy: 0.7727\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0315 - accuracy: 0.7727\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0003 - accuracy: 0.7576\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0039 - accuracy: 0.7576\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0002 - accuracy: 0.7424\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9783 - accuracy: 0.7803\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9718 - accuracy: 0.7803\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9453 - accuracy: 0.7879\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9345 - accuracy: 0.7955\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9153 - accuracy: 0.7879\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9241 - accuracy: 0.7727\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8916 - accuracy: 0.8030\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9009 - accuracy: 0.7955\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8813 - accuracy: 0.7955\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8797 - accuracy: 0.7955\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8630 - accuracy: 0.8182\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8581 - accuracy: 0.7879\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8405 - accuracy: 0.8409\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8221 - accuracy: 0.8106\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8303 - accuracy: 0.8182\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8091 - accuracy: 0.8182\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8159 - accuracy: 0.8106\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8006 - accuracy: 0.8182\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7988 - accuracy: 0.8409\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7859 - accuracy: 0.8485\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7747 - accuracy: 0.8485\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7761 - accuracy: 0.8333\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.8409\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.8485\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7443 - accuracy: 0.8409\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.8333\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7337 - accuracy: 0.8409\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.8333\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7178 - accuracy: 0.8409\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.8788\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.8561\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.8333\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7073 - accuracy: 0.8409\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6874 - accuracy: 0.8485\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.8485\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.8712\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.8939\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.8636\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.8485\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.8864\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.8485\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.8636\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.8864\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.8788\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.8636\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.8561\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.8788\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.8864\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.9091\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.9015\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.9167\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.8864\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.8788\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8864\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.9015\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.8788\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.8939\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8939\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.8561\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.8788\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.8864\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.9242\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.8864\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.9015\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.9015\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.8939\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.8864\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.8712\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.8788\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.8864\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.8939\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.8864\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.9091\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.9015\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.9167\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.8939\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.9091\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.9167\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.9015\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.8864\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.8939\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.9015\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.8864\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.9242\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.9167\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.9167\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.9091\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.9091\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.8939\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.8864\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.9015\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.9318\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.9015\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.9242\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.9242\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.9242\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.9242\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.9091\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.9167\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.9394\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.9091\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.9167\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.9167\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.9242\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.9167\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.9091\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.9167\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.9242\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.9242\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.9394\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.9394\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.9091\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.9470\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.9394\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.9318\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.9167\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.9470\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.9394\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.9394\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.9091\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.9394\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.9091\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.9318\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.9545\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.9318\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.9394\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.9318\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.9545\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.9318\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.9394\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.9470\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.9470\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.9318\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.9545\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.9242\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.9318\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.9545\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.9394\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.9167\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.9394\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.9545\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.9545\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.9545\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.9545\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.9545\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.9697\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.9470\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.9394\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.9470\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.9470\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.9318\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9545\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.9545\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.9697\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.9621\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.9545\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.9470\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.9545\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.9394\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.9545\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.9697\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.9621\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.9470\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.9470\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.9470\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.9545\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.9773\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.9545\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.9394\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.9697\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.9621\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.9470\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9545\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.9697\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.9394\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.9394\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.9621\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.9470\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.9545\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.9545\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.9470\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.9697\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.9697\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.9545\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.9545\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.9697\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2826 - accuracy: 0.9621\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.9470\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.9621\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.9545\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.9697\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.9394\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.9621\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.9697\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2761 - accuracy: 0.9470\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9621\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.9545\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.9697\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.9697\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.9545\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9697\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.9697\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.9773\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.9697\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.9773\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2733 - accuracy: 0.9697\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9545\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.9621\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2592 - accuracy: 0.9470\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9848\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.9697\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.9773\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.9848\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9621\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.9848\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.9773\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2548 - accuracy: 0.9697\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9621\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.9848\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.9773\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9848\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9848\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2312 - accuracy: 0.9848\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.9621\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2452 - accuracy: 0.9773\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.9773\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.9697\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.9621\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2414 - accuracy: 0.9773\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9621\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2248 - accuracy: 0.9924\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9848\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2258 - accuracy: 0.9621\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.9697\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9545\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9697\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9621\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9697\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9773\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.9621\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.9773\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2347 - accuracy: 0.9697\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9621\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2270 - accuracy: 0.9848\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2303 - accuracy: 0.9697\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9697\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2139 - accuracy: 0.9848\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2224 - accuracy: 0.9848\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9848\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2359 - accuracy: 0.9621\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2264 - accuracy: 0.9621\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.9621\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.9697\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9848\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9773\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9621\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2283 - accuracy: 0.9773\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2185 - accuracy: 0.9773\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2271 - accuracy: 0.9621\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2243 - accuracy: 0.9848\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9848\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9848\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9773\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2098 - accuracy: 0.9773\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9621\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9848\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2045 - accuracy: 0.9773\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9773\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2055 - accuracy: 0.9773\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f91e3c8a2f0>"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emoji_text_300d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.300d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_300d.preprocess(X_train,Y_train)\n",
        "model_300 = emoji_text_300d.train(X_train,Y_train,epochs=300)\n",
        "model_300.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-yBUmHET0B3",
        "outputId": "b74a4e05-ad19-416e-8ae2-b1f3c40c697f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49, 300) (49, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f91e02140d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4916 - accuracy: 0.8776\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.4915929436683655, 0.8775510191917419)"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss,accuracy= emoji_text_300d.test(model_300,X_test,Y_test)\n",
        "loss,accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SyPwsWKUDEj",
        "outputId": "656251a5-d746-406f-8095-c59e38200bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('‚öæ', 0.127455472946167)"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'I workout in gym'\n",
        "emoji,timer = emoji_text_300d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhU93QzSURXE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
