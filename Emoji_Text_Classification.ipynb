{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3MJkVdQJi1R6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KyC9UMKJSkOu"
      },
      "outputs": [],
      "source": [
        "class EmojiTextClassifier:\n",
        "    def __init__(self,vector_shape):\n",
        "        self.vector_shape = vector_shape\n",
        "\n",
        "    def load_dataset(self,dataset_path):\n",
        "        self.df = pd.read_csv(dataset_path)\n",
        "        self.X = np.array(self.df['sentence'],dtype=object)\n",
        "        self.Y = np.array(self.df['label'],dtype=int)\n",
        "        return self.X,self.Y\n",
        "\n",
        "    def load_features_vector(self,file_txt_path):\n",
        "        self.f = open(file_txt_path,encoding='utf-8')\n",
        "        self.word_vectors = {}\n",
        "        for line in self.f:\n",
        "            line = line.strip().split()\n",
        "            word = line[0]\n",
        "            vector = np.array(line[1:],dtype=np.float64)\n",
        "            self.word_vectors[word] = vector\n",
        "\n",
        "        return self.word_vectors\n",
        "\n",
        "\n",
        "    def sentence_to_feature_vectors_avg(self,sentence):\n",
        "          self.sentence = sentence.lower()\n",
        "          words = self.sentence.strip().split(' ')\n",
        "          sum_vectors = np.zeros((self.vector_shape,))\n",
        "          for word in words:\n",
        "              sum_vectors += self.word_vectors[word]\n",
        "\n",
        "          avg_words = sum_vectors / len(words)\n",
        "\n",
        "          return avg_words\n",
        "\n",
        "\n",
        "    def preprocess(self,X,Y):\n",
        "        self.X_avg = []\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        for x in X:\n",
        "            self.X_avg.append(self.sentence_to_feature_vectors_avg(x))\n",
        "\n",
        "\n",
        "        self.X_avg = np.array(self.X_avg).astype('float32')\n",
        "        self.Y_one_hot = tf.keras.utils.to_categorical(self.Y,num_classes=5)\n",
        "\n",
        "        return self.X_avg,self.Y_one_hot\n",
        "\n",
        "    def load_model(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dropout(0.1),\n",
        "            tf.keras.layers.Dense(5,input_shape=(self.vector_shape,),activation='softmax')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    def train(self,X_train,Y_train,epochs):\n",
        "        #self.input_shape =input_shape\n",
        "        self.X_train_avg,self.Y_train_one_hot = self.preprocess(X_train,Y_train)\n",
        "        print(self.X_train_avg.shape,self.Y_train_one_hot.shape)\n",
        "        self.model = self.load_model()\n",
        "        self.model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        #self.model.fit(self.X_train_avg,self.Y_train_one_hot,epochs)\n",
        "        return self.model\n",
        "\n",
        "    def test(self,model,X_test,Y_test):\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        #self.X_test_avg,self.Y_test_one_hot = self.preprocess(self.X_test,self.Y_test)\n",
        "        self.X_avg = []\n",
        "        self.new_Y_test = []\n",
        "        i = 0\n",
        "\n",
        "        for index,x in enumerate(self.X_test):\n",
        "            if x.endswith('\\t') == True:\n",
        "              self.X_avg.append(self.sentence_to_feature_vectors_avg(x))\n",
        "              self.new_Y_test.append(self.Y_test[index])\n",
        "\n",
        "\n",
        "\n",
        "        self.X_avg = np.array(self.X_avg)\n",
        "        self.new_Y_test = np.array(self.new_Y_test)\n",
        "        self.Y_one_hot = tf.keras.utils.to_categorical(self.new_Y_test,num_classes=5)\n",
        "        print(np.shape(self.X_avg),np.shape(self.Y_one_hot))\n",
        "\n",
        "        accuracy,loss = model.evaluate(self.X_avg,self.Y_one_hot)\n",
        "\n",
        "        return accuracy,loss\n",
        "\n",
        "    def label_to_emoji(self,label):\n",
        "        self.label = label\n",
        "        emojies=['‚ù§Ô∏è','‚öæ','üòä','üòû','üç¥']\n",
        "\n",
        "        return emojies[self.label]\n",
        "\n",
        "    def predict(self,sentece_test):\n",
        "        start_time = time.time()\n",
        "        self.sentence_test = sentece_test\n",
        "        self.my_test_avg = self.sentence_to_feature_vectors_avg(self.sentence_test)\n",
        "        self.my_test_avg = np.array([self.my_test_avg])\n",
        "        self.result = self.model.predict(self.my_test_avg)\n",
        "        y_pred = np.argmax(self.result)\n",
        "\n",
        "        return self.label_to_emoji(y_pred),time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDTk0DJZ8s3S"
      },
      "source": [
        "## 50 Dimention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a7mnieGdHIxv"
      },
      "outputs": [],
      "source": [
        "emoji_text_50d = EmojiTextClassifier(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJprK7wxyUB6",
        "outputId": "b83f899d-e3d1-4e23-a1a9-9fb1fa866820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(132, 50) (132, 5)\n",
            "Epoch 1/300\n",
            "5/5 [==============================] - 3s 13ms/step - loss: 1.8070 - accuracy: 0.1742\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7692 - accuracy: 0.1818\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7442 - accuracy: 0.1818\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7418 - accuracy: 0.2273\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7587 - accuracy: 0.1970\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7360 - accuracy: 0.2500\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7081 - accuracy: 0.2273\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6828 - accuracy: 0.2273\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6647 - accuracy: 0.2803\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6496 - accuracy: 0.2652\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6421 - accuracy: 0.2576\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6549 - accuracy: 0.2879\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6445 - accuracy: 0.3561\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6308 - accuracy: 0.2576\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6178 - accuracy: 0.3106\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6140 - accuracy: 0.2500\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5989 - accuracy: 0.3409\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6068 - accuracy: 0.2879\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5905 - accuracy: 0.3258\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5667 - accuracy: 0.3333\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5603 - accuracy: 0.3258\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5154 - accuracy: 0.3636\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5462 - accuracy: 0.3712\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5615 - accuracy: 0.3258\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5041 - accuracy: 0.3712\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5097 - accuracy: 0.4015\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5371 - accuracy: 0.3258\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5142 - accuracy: 0.3636\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4936 - accuracy: 0.3636\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4799 - accuracy: 0.3939\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4915 - accuracy: 0.3788\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4555 - accuracy: 0.4015\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4179 - accuracy: 0.4242\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4659 - accuracy: 0.3561\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4241 - accuracy: 0.4091\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4661 - accuracy: 0.3485\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4064 - accuracy: 0.4242\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4572 - accuracy: 0.3561\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4606 - accuracy: 0.3712\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3952 - accuracy: 0.4773\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4131 - accuracy: 0.4091\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4332 - accuracy: 0.3712\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3756 - accuracy: 0.4091\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3514 - accuracy: 0.5076\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4047 - accuracy: 0.4242\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3641 - accuracy: 0.4470\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3538 - accuracy: 0.4242\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3523 - accuracy: 0.4470\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3940 - accuracy: 0.3864\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3454 - accuracy: 0.4318\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3484 - accuracy: 0.3939\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3113 - accuracy: 0.4621\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3266 - accuracy: 0.4318\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3227 - accuracy: 0.4242\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2871 - accuracy: 0.4697\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3123 - accuracy: 0.5076\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2912 - accuracy: 0.4848\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2677 - accuracy: 0.4924\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2704 - accuracy: 0.4924\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2847 - accuracy: 0.5076\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3056 - accuracy: 0.4470\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2491 - accuracy: 0.4848\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2832 - accuracy: 0.5000\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2401 - accuracy: 0.6061\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2484 - accuracy: 0.5227\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2366 - accuracy: 0.5227\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2108 - accuracy: 0.5606\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2226 - accuracy: 0.5152\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2071 - accuracy: 0.5530\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2259 - accuracy: 0.5379\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2356 - accuracy: 0.4773\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2123 - accuracy: 0.5606\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2103 - accuracy: 0.5606\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2067 - accuracy: 0.5682\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1774 - accuracy: 0.5758\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2106 - accuracy: 0.5682\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1916 - accuracy: 0.5758\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1748 - accuracy: 0.5985\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1696 - accuracy: 0.6288\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1976 - accuracy: 0.5682\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1324 - accuracy: 0.6515\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1854 - accuracy: 0.5985\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1710 - accuracy: 0.5909\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1648 - accuracy: 0.5833\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1056 - accuracy: 0.6136\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1478 - accuracy: 0.5758\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1575 - accuracy: 0.5909\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1376 - accuracy: 0.5985\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1109 - accuracy: 0.6439\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1094 - accuracy: 0.6364\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1512 - accuracy: 0.5758\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1188 - accuracy: 0.5985\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1482 - accuracy: 0.6061\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0959 - accuracy: 0.6439\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1225 - accuracy: 0.5833\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1224 - accuracy: 0.6061\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1266 - accuracy: 0.6212\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0918 - accuracy: 0.6591\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0895 - accuracy: 0.5985\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0809 - accuracy: 0.6061\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0845 - accuracy: 0.6667\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0965 - accuracy: 0.6364\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0512 - accuracy: 0.6591\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0743 - accuracy: 0.6061\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0406 - accuracy: 0.7121\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0659 - accuracy: 0.6439\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0782 - accuracy: 0.6667\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0602 - accuracy: 0.6288\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0464 - accuracy: 0.6591\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0794 - accuracy: 0.6136\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0454 - accuracy: 0.6288\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.6894\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0431 - accuracy: 0.6364\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0562 - accuracy: 0.6667\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0454 - accuracy: 0.6439\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0239 - accuracy: 0.6667\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0422 - accuracy: 0.6515\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0038 - accuracy: 0.7121\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0188 - accuracy: 0.6515\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0378 - accuracy: 0.6439\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.6288\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9800 - accuracy: 0.6818\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0311 - accuracy: 0.6742\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0101 - accuracy: 0.6439\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0149 - accuracy: 0.6591\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9968 - accuracy: 0.6364\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9926 - accuracy: 0.6591\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.6364\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9811 - accuracy: 0.6818\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.6515\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.6742\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9623 - accuracy: 0.7273\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9900 - accuracy: 0.6818\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0308 - accuracy: 0.6364\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9776 - accuracy: 0.6970\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9922 - accuracy: 0.6515\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9562 - accuracy: 0.7500\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0085 - accuracy: 0.6288\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9759 - accuracy: 0.6591\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9699 - accuracy: 0.7045\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9540 - accuracy: 0.7121\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9320 - accuracy: 0.7121\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9892 - accuracy: 0.6667\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9616 - accuracy: 0.6742\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9693 - accuracy: 0.6894\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9375 - accuracy: 0.6894\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9594 - accuracy: 0.6742\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9443 - accuracy: 0.7045\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9369 - accuracy: 0.7045\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9475 - accuracy: 0.7273\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9467 - accuracy: 0.7045\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9274 - accuracy: 0.6894\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9278 - accuracy: 0.7273\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9238 - accuracy: 0.6742\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9424 - accuracy: 0.6818\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8904 - accuracy: 0.7424\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9382 - accuracy: 0.7197\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9561 - accuracy: 0.6591\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9326 - accuracy: 0.6818\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8924 - accuracy: 0.7045\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9289 - accuracy: 0.6818\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9321 - accuracy: 0.6667\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8875 - accuracy: 0.7197\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8865 - accuracy: 0.7273\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9088 - accuracy: 0.7045\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9173 - accuracy: 0.7273\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8676 - accuracy: 0.7424\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8748 - accuracy: 0.7576\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8974 - accuracy: 0.7348\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8802 - accuracy: 0.7576\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8701 - accuracy: 0.7197\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9178 - accuracy: 0.6970\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8903 - accuracy: 0.7197\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8797 - accuracy: 0.7576\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9042 - accuracy: 0.7500\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8858 - accuracy: 0.6970\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8890 - accuracy: 0.6818\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8790 - accuracy: 0.7576\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8953 - accuracy: 0.6742\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8807 - accuracy: 0.6742\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8611 - accuracy: 0.7197\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.7121\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8610 - accuracy: 0.7424\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8652 - accuracy: 0.7348\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8786 - accuracy: 0.7273\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8459 - accuracy: 0.7197\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8818 - accuracy: 0.7197\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8394 - accuracy: 0.6970\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8684 - accuracy: 0.6970\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8325 - accuracy: 0.7576\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8431 - accuracy: 0.7424\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8639 - accuracy: 0.7045\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8672 - accuracy: 0.7424\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8504 - accuracy: 0.7424\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8380 - accuracy: 0.7727\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8440 - accuracy: 0.7273\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8266 - accuracy: 0.7500\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8522 - accuracy: 0.7045\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8585 - accuracy: 0.7424\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8272 - accuracy: 0.7424\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8519 - accuracy: 0.7500\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8211 - accuracy: 0.7803\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8325 - accuracy: 0.7803\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8157 - accuracy: 0.7197\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8053 - accuracy: 0.7652\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8536 - accuracy: 0.7273\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8302 - accuracy: 0.7500\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8298 - accuracy: 0.7197\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8388 - accuracy: 0.7273\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8078 - accuracy: 0.7424\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8440 - accuracy: 0.7197\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8219 - accuracy: 0.7500\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8135 - accuracy: 0.7652\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8343 - accuracy: 0.7348\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8257 - accuracy: 0.7424\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8097 - accuracy: 0.7348\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7970 - accuracy: 0.7500\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.7121\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8256 - accuracy: 0.7348\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8036 - accuracy: 0.7273\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8103 - accuracy: 0.7045\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7961 - accuracy: 0.7273\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8059 - accuracy: 0.7500\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7967 - accuracy: 0.7803\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7746 - accuracy: 0.7652\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7996 - accuracy: 0.7424\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8135 - accuracy: 0.7424\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7898 - accuracy: 0.6970\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8123 - accuracy: 0.6894\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7843 - accuracy: 0.7652\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7955 - accuracy: 0.7121\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7628 - accuracy: 0.7803\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7891 - accuracy: 0.7652\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8004 - accuracy: 0.7424\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8029 - accuracy: 0.7273\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7893 - accuracy: 0.7273\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7752 - accuracy: 0.7576\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8045 - accuracy: 0.7500\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7535 - accuracy: 0.7803\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7805 - accuracy: 0.7424\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7695 - accuracy: 0.7500\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.7955\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.7652\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7627 - accuracy: 0.7652\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.7121\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7504 - accuracy: 0.7424\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7424\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8070 - accuracy: 0.7197\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7294 - accuracy: 0.7727\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7948 - accuracy: 0.7500\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7910 - accuracy: 0.7348\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7480 - accuracy: 0.7652\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7482 - accuracy: 0.7955\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7813 - accuracy: 0.7197\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7750 - accuracy: 0.7197\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7404 - accuracy: 0.7727\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7707 - accuracy: 0.7500\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7878 - accuracy: 0.7424\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.7652\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7811 - accuracy: 0.7652\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7466 - accuracy: 0.7273\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7262 - accuracy: 0.7879\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7277 - accuracy: 0.7727\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7607 - accuracy: 0.7500\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7525 - accuracy: 0.7273\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7418 - accuracy: 0.7424\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7500 - accuracy: 0.7424\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7646 - accuracy: 0.7045\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.7879\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7390 - accuracy: 0.7576\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7733 - accuracy: 0.7197\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7526 - accuracy: 0.7273\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7435 - accuracy: 0.7879\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.7424\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7087 - accuracy: 0.8258\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7257 - accuracy: 0.7727\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7471 - accuracy: 0.7197\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.7803\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7621 - accuracy: 0.7348\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7479 - accuracy: 0.7500\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7337 - accuracy: 0.7803\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7608 - accuracy: 0.7424\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7399 - accuracy: 0.8030\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.7803\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.8182\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7208 - accuracy: 0.7879\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.8030\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7107 - accuracy: 0.7576\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7574 - accuracy: 0.7273\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7106 - accuracy: 0.7955\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7163 - accuracy: 0.7727\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6987 - accuracy: 0.8258\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7272 - accuracy: 0.7576\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7231 - accuracy: 0.8030\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.7727\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7243 - accuracy: 0.8182\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7070 - accuracy: 0.7727\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7172 - accuracy: 0.7727\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7202 - accuracy: 0.7879\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7244 - accuracy: 0.7727\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a9d97cf6500>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train,Y_train = emoji_text_50d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test= emoji_text_50d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')\n",
        "\n",
        "emoji_text_50d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.50d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_50d.preprocess(X_train,Y_train)\n",
        "model=emoji_text_50d.train(X_train,Y_train,epochs=300)\n",
        "model.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ymOM6OR1Yb-",
        "outputId": "f321ff22-efe4-4fdc-dfd1-051e2d07e86d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49, 50) (49, 5)\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7332 - accuracy: 0.7551\n"
          ]
        }
      ],
      "source": [
        "accuracy,loss = emoji_text_50d.test(model,X_test,Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTP7FPwcgxQx",
        "outputId": "1db78a23-3d0e-4f90-93f0-d98fa3988c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('üòä', 0.06578493118286133)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'the Weather is Sunny'\n",
        "emoji,timer = emoji_text_50d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhPll3d689WU"
      },
      "source": [
        "## 100 Dimention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PpacYOMKNb2h"
      },
      "outputs": [],
      "source": [
        "emoji_text_100d = EmojiTextClassifier(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD2WfmZC1Enp"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test = emoji_text_100d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')\n",
        "\n",
        "emoji_text_100d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.100d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_100d.preprocess(X_train,Y_train)\n",
        "model_100 = emoji_text_100d.train(X_train,Y_train,epochs=300)\n",
        "model_100.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDbAt3Ig9ScK",
        "outputId": "c9caebdc-fb1f-494c-fb5d-5fd5b100a506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49, 100) (49, 5)\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6593 - accuracy: 0.7959\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.6593421697616577, 0.795918345451355)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval = emoji_text_100d.test(model_100,X_test,Y_test)\n",
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmyAqYQujlQX",
        "outputId": "ff1ff934-2d95-4338-ace2-96e25c9df42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('üòä', 0.09525656700134277)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'the Weather is Sunny'\n",
        "emoji,timer = emoji_text_100d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zMYVdrBTcVs"
      },
      "source": [
        "## 200 Dimention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6nZ2oLmjTCrn"
      },
      "outputs": [],
      "source": [
        "emoji_text_200d = EmojiTextClassifier(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "M3dJ8lHyTfUi"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = emoji_text_200d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test = emoji_text_200d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIWh31ksTkMv",
        "outputId": "65817d9a-a61d-42ae-8082-22e50d938509"
      },
      "outputs": [],
      "source": [
        "emoji_text_200d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.200d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_200d.preprocess(X_train,Y_train)\n",
        "model_200 = emoji_text_200d.train(X_train,Y_train,epochs=300)\n",
        "model_200.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICRpRElATmQ5",
        "outputId": "b716da00-ef80-44ab-ba67-c8fb7fec5a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49, 200) (49, 5)\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5209 - accuracy: 0.8367\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.5209062695503235, 0.8367347121238708)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss,accuracy= emoji_text_200d.test(model_200,X_test,Y_test)\n",
        "loss,accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18c7evC-TwsP",
        "outputId": "7e64c7f6-c497-4646-fed9-d9f999c7b9e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('üòä', 0.08133244514465332)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'the Weather is Sunny'\n",
        "emoji,timer = emoji_text_200d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlIUDI5oUATG"
      },
      "source": [
        "## 300 Dimention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mcSTO32FT6T-"
      },
      "outputs": [],
      "source": [
        "emoji_text_300d = EmojiTextClassifier(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PazSdqeiUEHG"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = emoji_text_300d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test,Y_test = emoji_text_300d.load_dataset('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQTd4rG_UH2G",
        "outputId": "ae85713e-6835-4232-a034-7570bdca17eb"
      },
      "outputs": [],
      "source": [
        "emoji_text_300d.load_features_vector('/content/drive/MyDrive/Emoji_Text_Classification/glove-6B/glove.6B.300d.txt')\n",
        "X_train_avg,Y_train_one_hot = emoji_text_300d.preprocess(X_train,Y_train)\n",
        "model_300 = emoji_text_300d.train(X_train,Y_train,epochs=300)\n",
        "model_300.fit(X_train_avg,Y_train_one_hot,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DsGyKryUK1O",
        "outputId": "65e0e08b-56b9-4386-a8e8-8cb46676eb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49, 300) (49, 5)\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4601 - accuracy: 0.8980\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.46014684438705444, 0.8979591727256775)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss,accuracy= emoji_text_300d.test(model_300,X_test,Y_test)\n",
        "loss,accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP93DiwOUNj5",
        "outputId": "ade6c850-839f-4068-d764-168822e74237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('‚öæ', 0.07652163505554199)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infrence = 'I workout in gym'\n",
        "emoji,timer = emoji_text_300d.predict(infrence)\n",
        "emoji,timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99nGzmG5UPTO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
